{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract meetup data using meetup API \n",
    "\n",
    "Extract the meetup data of categories, groups, members, events and rsvps to build our recommendation engine. \n",
    "[Meetup api](https://www.meetup.com/meetup_api/)\n",
    "\n",
    "Note: These scripts will work only with Python 2.7 and not with Python 3.0+ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/30 (10 seconds remaining)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import codecs\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import datetime\n",
    "import re\n",
    "import random, copy\n",
    "import os\n",
    "\n",
    "#Add your key here\n",
    "api_key = ''\n",
    "\n",
    "UTF8Writer = codecs.getwriter('utf8')\n",
    "sys.stdout = UTF8Writer(sys.stdout)\n",
    "url_string = \"http://api.meetup.com//\"\n",
    "\n",
    "import meetup.api\n",
    "client = meetup.api.Client(api_key,overlimit_wait=True)\n",
    "a = client.GetCategories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fetch the category,cities,topic_categories information using meetup.api package\n",
    "\n",
    "## Categories\n",
    "categories_df = pd.read_json(json.dumps(a.results))\n",
    "categories_df.to_csv('categories_new.csv', index = False)\n",
    "\n",
    "## Cities\n",
    "cities = client.GetCities(country='US', state='TX')\n",
    "cities_df = pd.read_json(json.dumps(cities.results))\n",
    "cities_df.to_csv('cities_new.csv',index=False)\n",
    "\n",
    "## Topics\n",
    "topic_categories = client.GetTopicCategories()\n",
    "topic_catg_df = pd.read_json(json.dumps(topic_categories.results))\n",
    "topic_catg_df.to_csv('topic_categories_new.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read Categories File\n",
    "df = pd.read_csv('categories_new.csv')\n",
    "catg_id = df.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of our analysis, we extracted all the Meetup groups from Austin, Texas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to fetch groups\n",
    "def getgroups(catg_id,off_val):\n",
    "    group = client.GetGroups(category_id = catg_id,offset = off_val,location = 'Austin')\n",
    "    result = group.results\n",
    "    RES = json_normalize(result)\n",
    "    return RES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fetch unique groups \n",
    "cwd = os.getcwd()\n",
    "group_id_extract = pd.DataFrame([])\n",
    "dat_list = []\n",
    "for i in catg_id:\n",
    "    print (i)\n",
    "    try:\n",
    "        data = pd.read_csv(cwd+'\\\\groups_'+str(i)+'.csv',usecols=[13,4], index_col = False, header=0)\n",
    "        dat_list.append(data)\n",
    "    except:\n",
    "        continue\n",
    "group_id_extract = pd.concat(dat_list)\n",
    "group_id_new = group_id_extract[group_id_extract['country']=='US']['id']\n",
    "group_id_US = group_id_new.drop_duplicates().reset_index(drop=True)\n",
    "unique_groups = np.array(group_id_US)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create groups files for every category\n",
    "for i in range(len(catg_id)):\n",
    "    groups = pd.DataFrame([])\n",
    "    for j in range(10000):\n",
    "        try:\n",
    "            result = getgroups(catg_id[i],j)\n",
    "        except:\n",
    "            continue\n",
    "        if len(result) != 0:\n",
    "            groups = groups.append(result)\n",
    "        else:\n",
    "            break\n",
    "    groups.to_csv('groups_'+ str(catg_id[i]) +'.csv',index=False,encoding='utf-8')\n",
    "\n",
    "## Concatenate all the group files that were fetched indiviually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Call the Meetup API\n",
    "def get_results(string, params):\n",
    "    request = requests.get(string,params=params)\n",
    "    return request.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to fetch members data\n",
    "def get_members( group_id, index,num_groups ):\n",
    "    result =[]\n",
    "    prev=[]\n",
    "    for offset in range(10000):\n",
    "        count = 0\n",
    "        while True:\n",
    "            params = {\"sign\":\"true\", \"key\":api_key, \"page\":200, \"offset\":offset, \"group_id\":group_id}\n",
    "            try:\n",
    "                time.sleep(0.1)\n",
    "                temp = get_results(url_string + \"2/members\", params)\n",
    "            except (ValueError, ChunkedEncodingError):\n",
    "                continue\n",
    "            break\n",
    "        if len(temp['results']) != 0:\n",
    "            if prev == temp['results']:\n",
    "                value = pd.DataFrame(pd.io.json.json_normalize(result))\n",
    "                value['group_id']=[group_id] *len(value)\n",
    "                \n",
    "                value.to_csv(\"member_\"+str(group_id)+'.csv', encoding = 'utf-8',sep=str(\",\"))\n",
    "                return None\n",
    "            result = result + temp['results']\n",
    "            sys.stdout.write('\\r' + \"Processed: \" + str(len(result)) + \" events for group number \" + str(group_id) +\\\n",
    "                             \". Progress: \"+ str(index) +'/'+str(num_groups))\n",
    "            sys.stdout.flush()\n",
    "            prev = copy.deepcopy(temp['results'])\n",
    "        else:\n",
    "            break\n",
    "    sys.stdout.write('\\r' + \" \"*150 + '\\r')\n",
    "    value = pd.DataFrame(pd.io.json.json_normalize(result))\n",
    "    value['group_id']=[group_id] *len(value)\n",
    "    value.to_csv(\"member_\"+str(group_id)+'.csv', encoding = 'utf-8',sep=str(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fetch members and extract to csv\n",
    "num_groups = len(unique_groups)\n",
    "for index, group_id in enumerate(unique_groups):\n",
    "    (get_members(group_id,index, num_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to fetch events\n",
    "def getevents(group_id,off_val):\n",
    "    event = client.GetEvents(group_id = group_id, offset = off_val)\n",
    "    result = event.results\n",
    "    RES = json_normalize(result)\n",
    "    return RES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fetch events and extract to csv\n",
    "events = pd.DataFrame([])\n",
    "for i in range(len(unique_groups)):\n",
    "    for j in range(10000):\n",
    "        result = getevents(unique_groups.id[i], j)\n",
    "        if len(result) != 0:\n",
    "            events = events.append(result)\n",
    "        else:\n",
    "            break\n",
    "events.to_csv('events.csv',index=False,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read the Austin groups into a csv file\n",
    "austin_groups = pd.read_csv(\"groups_austin.csv\")\n",
    "austin_groups_ids = np.array((austin_groups.id))\n",
    "austin_groups_ids=list(set(list(austin_groups_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fetch events and extract to csv\n",
    "events = pd.DataFrame([])\n",
    "for i in range(len(austin_groups_ids)):\n",
    "    for j in range(10000):\n",
    "        result = getevents(temp_group_ids[i], j)\n",
    "        if len(result) != 0:\n",
    "            events = events.append(result)\n",
    "        else:\n",
    "            break\n",
    "events.to_csv('events_new_100_rest.csv',index=False,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sijop\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:4: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Store and reading files before fetching the RSVP data\n",
    "events_new = pd.read_csv(\"events_new.csv\")\n",
    "events_new_100_rest = pd.read_csv('events_new_100_rest.csv')\n",
    "events_all_new = pd.concat([events_new,events_new_100_rest])\n",
    "events_all_new.to_csv('events_all_new.csv',index=False,encoding='utf-8')\n",
    "events_all_new = pd.read_csv(\"events_all_new.csv\")\n",
    "event_ids = list(events_all_new.id)\n",
    "#austin_groups_ids = np.array((events_new.id))\n",
    "#austin_groups_ids=list(set(list(austin_groups_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to fetch RSVP data\n",
    "def getrsvps(event_id,off_val):\n",
    "    event = client.GetRsvps(event_id = event_id, offset = off_val)\n",
    "    result = event.results\n",
    "    RES = json_normalize(result)\n",
    "    return RES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sijop\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "temp_event_ids = event_ids[100:]\n",
    "tracker = list(range(1,40000,1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetch events and extract to csv\n",
    "rsvps = pd.DataFrame([])\n",
    "for i in range(len(temp_event_ids)):\n",
    "    for j in range(10000):\n",
    "        try:\n",
    "            if i in tracker:\n",
    "                print (\"------------------------------\"+ str(i) + \"------------------------\") \n",
    "            result = getrsvps(temp_event_ids[i], j)\n",
    "            if len(result) != 0:\n",
    "                rsvps = rsvps.append(result)\n",
    "            else:\n",
    "                break\n",
    "        except:\n",
    "            continue\n",
    "rsvps.to_csv('rsvps_new_100_rest_all.csv',index=False,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Store all the RSVP data \n",
    "rsvps_new = pd.read_csv(\"rsvps_new.csv\")\n",
    "rsvps_new_100_rest_all = pd.read_csv('rsvps_new_100_rest_all.csv')\n",
    "\n",
    "rsvps_all_new = pd.concat([rsvps_new,rsvps_new_100_rest_all])\n",
    "rsvps_all_new.to_csv('rsvps_all_new.csv',index=False,encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
